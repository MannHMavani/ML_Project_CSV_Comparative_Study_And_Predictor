<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
    <link href="{{ url_for('static', path='/styles.css') }}" rel="stylesheet">
    <title>About Project</title>
</head>
<body class="bg-light">
    <div class="container mt-5">
        <div class="card shadow">
            <div class="card-header bg-primary text-white">
                <h1 class="card-title"><i class="fas fa-info-circle"></i> About Project</h1>
            </div>
            <div class="card-body">
               
                <p class="lead">
                    This project focuses on <strong>ADASYN (Adaptive Synthetic Sampling)</strong> to handle imbalanced datasets, particularly in the context of predicting heart disease. The goal is to improve the performance of machine learning models by balancing the dataset and then evaluating various classification algorithms to identify the best-performing model for heart disease prediction.
                </p>

                <h3 class="text-primary">Key Steps in the Project:</h3>
                <ol>
                    <li><strong>Data Preprocessing:</strong> The dataset is loaded and preprocessed to handle missing values using median imputation for numerical columns and mode imputation for categorical columns. Categorical variables are encoded using <code>LabelEncoder</code>, and numerical features are normalized using <code>MinMaxScaler</code>.</li>
                    <li><strong>Handling Imbalanced Data with ADASYN:</strong> The <strong>ADASYN</strong> technique is applied to balance the dataset by generating synthetic samples for the minority class. This helps in improving the performance of machine learning models on imbalanced datasets.</li>
                    <li><strong>Model Training and Evaluation:</strong> Multiple machine learning models are trained and evaluated, including Decision Tree, Na√Øve Bayes, K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Random Forest, AdaBoost, XGBoost, Logistic Regression, and Gradient Boosting. The models are evaluated based on accuracy.</li>
                    <li><strong>Detailed Evaluation of Random Forest:</strong> The Random Forest model is further evaluated using additional metrics such as Confusion Matrix, Classification Report, and AUC-ROC Score.</li>
                    <li><strong>K-Fold Cross-Validation:</strong> <strong>10-Fold Cross-Validation</strong> is performed to assess the robustness of the models. This technique helps in understanding how the models generalize to unseen data.</li>
                    <li><strong>Hyperparameter Tuning:</strong> <strong>GridSearchCV</strong> and <strong>RandomizedSearchCV</strong> are used for hyperparameter tuning of selected models (Random Forest, SVM, K-Nearest Neighbors, and XGBoost). The best hyperparameters are identified, and the models are retrained to improve their performance.</li>
                </ol>

                <h3 class="text-primary">Tools and Libraries Used:</h3>
                <ul>
                    <li><strong>Pandas:</strong> For data manipulation and preprocessing.</li>
                    <li><strong>Scikit-learn:</strong> For machine learning algorithms, cross-validation, and hyperparameter tuning.</li>
                    <li><strong>XGBoost:</strong> For implementing the XGBoost algorithm.</li>
                    <li><strong>Imbalanced-learn:</strong> For applying the ADASYN technique to handle imbalanced data.</li>
                    <li><strong>NumPy:</strong> For numerical computations.</li>
                </ul>

                <h3 class="text-primary">Additional Insights:</h3>
                <ul>
                    <li><strong>Model Performance Before Tuning:</strong> The initial evaluation of models before hyperparameter tuning showed that <strong>Random Forest</strong> and <strong>XGBoost</strong> performed the best, with accuracies of <strong>80.35%</strong> and <strong>80.17%</strong>, respectively.</li>
                    <li><strong>Model Performance After Tuning:</strong> After hyperparameter tuning, the <strong>Random Forest</strong> model achieved an accuracy of <strong>80.65%</strong>, while <strong>XGBoost</strong> improved to <strong>82.76%</strong>.</li>
                    <li><strong>Cross-Validation Results:</strong> The <strong>10-Fold Cross-Validation</strong> results indicated that <strong>Random Forest</strong> and <strong>XGBoost</strong> consistently performed well, with cross-validation accuracies of <strong>88.25%</strong> and <strong>88.12%</strong>, respectively.</li>
                    <li><strong>AUC-ROC Score:</strong> The <strong>Random Forest</strong> model achieved an <strong>AUC-ROC score of 0.8804</strong>, indicating strong performance in distinguishing between the two classes (heart disease and no heart disease).</li>
                </ul>

                <h3 class="text-primary">Conclusion:</h3>
                <p class="lead">
                    This project demonstrates the effectiveness of using <strong>ADASYN</strong> to handle imbalanced datasets and the importance of <strong>hyperparameter tuning</strong> in improving the performance of machine learning models, particularly in the healthcare domain. The results show that <strong>Random Forest</strong> and <strong>XGBoost</strong> are the best-performing models for predicting heart disease, with high accuracy and robustness across different evaluation metrics. Future work could focus on further optimizing these models and deploying them for real-world applications.
                </p>

                <h3 class="text-primary">Project Creator:</h3>
                <p class="lead">
                    This project was created by <strong>Mann Mavani</strong>. Special thanks to all contributors and libraries used to make this project possible.
                </p>

                <h3 class="text-primary">This project is a machine learning-based web application that allows users to:</h3>
                <ul>
                    <li>Upload a dataset in CSV format.</li>
                    <li>Train multiple machine learning models on the dataset.</li>
                    <li>Compare the performance of the models.</li>
                    <li>Make predictions using the best-performing model.</li>
                </ul>
                <h3 class="text-primary">The application supports the following machine learning models:</h3>
                <ul>
                    <li>Logistic Regression</li>
                    <li>K-Nearest Neighbors (KNN)</li>
                    <li>Naive Bayes</li>
                    <li>Support Vector Machine (SVM)</li>
                    <li>Decision Tree</li>
                    <li>Random Forest</li>
                </ul>
                <h3 class="text-primary">The project is built using:</h3>
                <ul>
                    <li><strong>FastAPI</strong> for the backend.</li>
                    <li><strong>Bootstrap</strong> and <strong>Font Awesome</strong> for the frontend.</li>
                    <li><strong>Scikit-learn</strong> for machine learning.</li>
                </ul>
                <a href="/" class="btn btn-primary"><i class="fas fa-home"></i> Go Back</a>
            </div>
        </div>
    </div>
</body>
</html>
